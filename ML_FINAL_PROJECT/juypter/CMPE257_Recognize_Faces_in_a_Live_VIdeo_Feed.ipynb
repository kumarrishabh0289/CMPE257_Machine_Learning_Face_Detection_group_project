{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "# Open a new thread to manage the external cv2 interaction\n",
    "cv2.startWindowThread()\n",
    "\n",
    "def plt_show(image, title=\"\"):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(image, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "    \n",
    "class FaceDetector(object):\n",
    "    def __init__(self, xml_path):\n",
    "        self.classifier = cv2.CascadeClassifier(xml_path)\n",
    "    \n",
    "    def detect(self, image, biggest_only=True):\n",
    "        scale_factor = 1.2\n",
    "        min_neighbors = 5\n",
    "        min_size = (30, 30)\n",
    "        biggest_only = True\n",
    "        flags = cv2.CASCADE_FIND_BIGGEST_OBJECT | \\\n",
    "                    cv2.CASCADE_DO_ROUGH_SEARCH if biggest_only else \\\n",
    "                    cv2.CASCADE_SCALE_IMAGE\n",
    "        faces_coord = self.classifier.detectMultiScale(image,\n",
    "                                                       scaleFactor=scale_factor,\n",
    "                                                       minNeighbors=min_neighbors,\n",
    "                                                       minSize=min_size,\n",
    "                                                       flags=flags)\n",
    "        return faces_coord\n",
    "    \n",
    "class VideoCamera(object):\n",
    "    def __init__(self, index=0):\n",
    "        self.video = cv2.VideoCapture(index)\n",
    "        self.index = index\n",
    "        print(self.video.isOpened())\n",
    "\n",
    "    def __del__(self):\n",
    "        self.video.release()\n",
    "    \n",
    "    def get_frame(self, in_grayscale=False):\n",
    "        _, frame = self.video.read()\n",
    "        if in_grayscale:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        return frame\n",
    "\n",
    "def cut_faces(image, faces_coord):\n",
    "    faces = []\n",
    "    \n",
    "    for (x, y, w, h) in faces_coord:\n",
    "        w_rm = int(0.3 * w / 2)\n",
    "        faces.append(image[y: y + h, x + w_rm: x + w - w_rm])\n",
    "         \n",
    "    return faces\n",
    "\n",
    "def normalize_intensity(images):\n",
    "    images_norm = []\n",
    "    for image in images:\n",
    "        is_color = len(image.shape) == 3 \n",
    "        if is_color:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        images_norm.append(cv2.equalizeHist(image))\n",
    "    return images_norm\n",
    "\n",
    "def resize(images, size=(50, 50)):\n",
    "    images_norm = []\n",
    "    for image in images:\n",
    "        if image.shape < size:\n",
    "            image_norm = cv2.resize(image, size, \n",
    "                                    interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            image_norm = cv2.resize(image, size, \n",
    "                                    interpolation=cv2.INTER_CUBIC)\n",
    "        images_norm.append(image_norm)\n",
    "\n",
    "    return images_norm\n",
    "\n",
    "def normalize_faces(frame, faces_coord):\n",
    "    faces = cut_faces(frame, faces_coord)\n",
    "    faces = normalize_intensity(faces)\n",
    "    faces = resize(faces)\n",
    "    return faces\n",
    "\n",
    "def draw_rectangle(image, coords):\n",
    "    for (x, y, w, h) in coords:\n",
    "        w_rm = int(0.2 * w / 2) \n",
    "        cv2.rectangle(image, (x + w_rm, y), (x + w - w_rm, y + h), \n",
    "                              (150, 150, 0), 8)\n",
    "\n",
    "def collect_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "    labels_dic = {}\n",
    "    people = [person for person in os.listdir(\"people/\")]\n",
    "    for i, person in enumerate(people):\n",
    "        labels_dic[i] = person\n",
    "        for image in os.listdir(\"people/\" + person):\n",
    "            images.append(cv2.imread(\"people/\" + person + '/' + image, 0))\n",
    "            labels.append(i)\n",
    "    return (images, np.array(labels), labels_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Load Images, load labels and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Trained Succesfully\n"
     ]
    }
   ],
   "source": [
    "images, labels, labels_dic = collect_dataset()\n",
    "\n",
    "rec_eig = cv2.face.EigenFaceRecognizer_create()\n",
    "rec_eig.train(images, labels)\n",
    "\n",
    "# needs at least two people \n",
    "rec_fisher = cv2.face.FisherFaceRecognizer_create()\n",
    "rec_fisher.train(images, labels)\n",
    "\n",
    "rec_lbph = cv2.face.LBPHFaceRecognizer_create()\n",
    "rec_lbph.train(images, labels)\n",
    "\n",
    "print (\"Models Trained Succesfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "detector = FaceDetector(\"xml/frontal_face.xml\")\n",
    "webcam = VideoCamera(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Rishu\n",
      "Confidence: 143\n"
     ]
    }
   ],
   "source": [
    "cv2.namedWindow(\"CMPE273\", cv2.WINDOW_AUTOSIZE)\n",
    "while True:\n",
    "    frame = webcam.get_frame()\n",
    "    faces_coord = detector.detect(frame, True) # detect more than one face\n",
    "    if len(faces_coord):\n",
    "        faces = normalize_faces(frame, faces_coord) # norm pipeline\n",
    "        for i, face in enumerate(faces): # for each detected face\n",
    "            collector = cv2.face.StandardCollector_create()\n",
    "            rec_lbph.predict_collect(face, collector)\n",
    "            conf = collector.getMinDist()\n",
    "            pred = collector.getMinLabel()\n",
    "            threshold = 140\n",
    "            print (\"Prediction: \" + labels_dic[pred].capitalize() + \"\\nConfidence: \" + str(round(conf)))\n",
    "            cv2.putText(frame, labels_dic[pred].capitalize(),\n",
    "                        (faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "        clear_output(wait = True)\n",
    "        draw_rectangle(frame, faces_coord) # rectangle around face\n",
    "    cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2, cv2.LINE_AA)\n",
    "    cv2.imshow(\"CMPE273\", frame) # live feed in external\n",
    "    if cv2.waitKey(40) & 0xFF == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Apply threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Ayushi\n",
      "Confidence: 131\n"
     ]
    }
   ],
   "source": [
    "cv2.namedWindow(\"CMPE273\", cv2.WINDOW_AUTOSIZE)\n",
    "while True:\n",
    "    frame = webcam.get_frame()\n",
    "    faces_coord = detector.detect(frame, False) # detect more than one face\n",
    "    if len(faces_coord):\n",
    "        faces = normalize_faces(frame, faces_coord) # norm pipeline\n",
    "        for i, face in enumerate(faces): # for each detected face\n",
    "            collector = cv2.face.StandardCollector_create()\n",
    "            rec_lbph.predict_collect(face, collector)\n",
    "            conf = collector.getMinDist()\n",
    "            pred = collector.getMinLabel()\n",
    "            threshold = 140\n",
    "            print (\"Prediction: \" + labels_dic[pred].capitalize() + \"\\nConfidence: \" + str(round(conf)))\n",
    "            clear_output(wait = True)\n",
    "            if conf < threshold: # apply threshold\n",
    "                cv2.putText(frame, labels_dic[pred].capitalize(),\n",
    "                            (faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Unknown\",\n",
    "                            (faces_coord[i][0], faces_coord[i][1]),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "        draw_rectangle(frame, faces_coord) # rectangle around face\n",
    "    cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2, cv2.LINE_AA)\n",
    "    cv2.imshow(\"CMPE273\", frame) # live feed in external\n",
    "    if cv2.waitKey(40) & 0xFF == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "del webcam\n",
    "webcam = VideoCamera(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d8ecbe2d33b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m                             cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n\u001b[0;32m     23\u001b[0m         \u001b[0mdraw_rectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaces_coord\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# rectangle around face\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),\n\u001b[0m\u001b[0;32m     25\u001b[0m                     cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2, cv2.LINE_AA)\n\u001b[0;32m     26\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PyData Tutorial\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# live feed in external\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "cv2.namedWindow(\"CMPE273\", cv2.WINDOW_AUTOSIZE)\n",
    "while True:\n",
    "    frame = webcam.get_frame()\n",
    "    faces_coord = detector.detect(frame, False) # detect more than one face\n",
    "    if len(faces_coord):\n",
    "        faces = normalize_faces(frame, faces_coord) # norm pipeline\n",
    "        for i, face in enumerate(faces): # for each detected face\n",
    "            collector = cv2.face.StandardCollector_create()\n",
    "            rec_lbph.predict_collect(face, collector)\n",
    "            conf = collector.getMinDist()\n",
    "            pred = collector.getMinLabel()\n",
    "            threshold = 140\n",
    "            print (\"Prediction: \" + labels_dic[pred].capitalize() + \"\\nConfidence: \" + str(round(conf)))\n",
    "            clear_output(wait = True)\n",
    "            if conf < threshold: # apply threshold\n",
    "                cv2.putText(frame, labels_dic[pred].capitalize(),\n",
    "                            (faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Unknown\",\n",
    "                            (faces_coord[i][0], faces_coord[i][1]),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "        draw_rectangle(frame, faces_coord) # rectangle around face\n",
    "    cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2, cv2.LINE_AA)\n",
    "    cv2.imshow(\"PyData Tutorial\", frame) # live feed in external\n",
    "    if cv2.waitKey(40) & 0xFF == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "del webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def draw_label(image, text, coord, conf, threshold):\n",
    "    if conf < threshold: # apply threshold \n",
    "        cv2.putText(image, text.capitalize(),\n",
    "                    coord,\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "    else:\n",
    "        cv2.putText(image, \"Unknown\",\n",
    "                    coord,\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def live_recognition(index, webcam):\n",
    "    global double_frame\n",
    "    detector = FaceDetector(\"xml/frontal_face.xml\")\n",
    "    while True:\n",
    "        frame = webcam.get_frame()\n",
    "        faces_coord = detector.detect(frame, False) # detect more than one face\n",
    "        if len(faces_coord):\n",
    "            faces = normalize_faces(frame, faces_coord) # norm pipeline\n",
    "            for i, face in enumerate(faces): # for each detected face\n",
    "                collector = cv2.face.MinDistancePredictCollector()\n",
    "                rec_lbph.predict(face, collector)\n",
    "                conf = collector.getDist()\n",
    "                pred = collector.getLabel()\n",
    "                threshold = 140\n",
    "                draw_label(frame, labels_dic[pred], \n",
    "                           (faces_coord[i][0], faces_coord[i][1] - 10), \n",
    "                           conf, threshold)\n",
    "            draw_rectangle(frame, faces_coord) # rectangle around face\n",
    "        cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2, \n",
    "                    cv2.LINE_AA)\n",
    "        if index == 0:\n",
    "            cv2.putText(frame, \"Laptop\", (frame.shape[1] - 100, 30),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, \"External\", (frame.shape[1] - 120, 30),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2, cv2.LINE_AA)\n",
    "        double_frame[0 : 481, index * 640 : (index +1 ) * 640] = frame # copy new frame to FS\n",
    "        cv2.imshow(\"CMPE273\", double_frame) # live feed in external\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "cv2.namedWindow(\"CMPE273\", cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty(\"CMPE273\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "# cv2.namedWindow(\"PyData Tutorial 1\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "webcam_0 = VideoCamera(0)\n",
    "webcam_1 = VideoCamera(1)\n",
    "\n",
    "single_frame = np.zeros_like(webcam_0.get_frame())\n",
    "double_frame = np.hstack((single_frame, single_frame))\n",
    "\n",
    "thread_0 = Thread(target = live_recognition, args = (0, webcam_0))\n",
    "thread_1 = Thread(target = live_recognition, args = (1, webcam_1))\n",
    "thread_0.start()\n",
    "thread_1.start()\n",
    "thread_1.join()\n",
    "thread_0.join()\n",
    "del webcam_0\n",
    "del webcam_1\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
